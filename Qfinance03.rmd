---
title: "Finacial time series modeling and forcasting with R"
author: "Vijaya Gagrani"
date: "July 2015"
output:
  slidy_presentation:
    keep_md: yes
  ioslides_presentation:
    keep_md: yes
    transition: faster
    widescreen: yes
  beamer_presentation: default
---

## Background and Objective

The basic assumption for time series analysis is that the data points are randomly distributed and have some dependency between data points close together in time but no dependency in data points far apart in time. These assumption can be explained by the stationarity and ergodicity concepts. 

In a stationary (weakly) stochastic process, mean and variance doesnâ€™t change over time. Whereas, in a strictly stationary, in addtion to the first two moments, the covariance stays stationary. In other words, in a strictly stochastic process no assumption is made about the strength of dependence between random data points in the sequence. The strength of dependence between random points in a stochastic process diminishes the farther apart the points become. This diminishing dependence assumption is captured by the concept of ergodicity. A stochastic process is ergodic if any two random points partitioned far apart in the sequence.

The autocovariances and autocorrelations are the measures of linear temporal dependence in a covariance stationary stochastic process, known as the autocorrelation function (ACF). This function revels the interrelationships within a time series or correlation between all pairs of data points that are exactly same steps apart.

An important class of linear time series models is the family of Autoregressive Integrated Moving Average (ARIMA) models, proposed by Box and Jenkins (1976). It assumes that the current value can depend only on the past values of the time series itself or on past values of some error term.

Moving average models are simple covariance stationary and ergodic time series models that can capture a wide variety of autocorrelation patterns. To create a covariance stationary and ergodic stochastic process in which yt and yt minus 1 are correlated but yt and yt minus j are not correlated for j less than 1, where the time dependence in the process only lasts for one period. These processes can be created using the first order moving average (MA (1)) model. The moving average parameter, theta determines the sign and magnitude of the correlation between yt and yt minus 1. Clearly, if theta equals to 0, yt exhibits no time dependence.

The presence of autocorrelation is one indication that an ARIMA model could be used to model the time series. From ACF plot, one can count number of significant autocorrelations, which is a useful estimate of the number of moving averages (MA) coefficients in the model. The plot for the wfc shows that only one MA coefficient is required.


```{r Set_ChunkOptions, echo=FALSE}
#Select Chunk and package options @ http://yihui.name/knitr/options
knitr::opts_chunk$set(comment = NA, echo= FALSE, message = FALSE, fig.align='center', warning = FALSE,cache=FALSE)

```

```{r Initial_Settings_n_Basic_Stat}
#set working directory
#setwd("C:/Users/gagranis/Documents/Finance/Coursera/qfinance")
options(digits=4, width=70)
#options(rpubs.upload.method = "internal")
library("forecast")
#cc returns from montly prices
 returns_lcc <- read.csv("~/Finance/Coursera/qfinance/returns_lcc.csv")
 # log prices
returns <- read.csv("~/Finance/Coursera/qfinance/returns.csv")
```

```{r}
# Test for no autocorrelation in returns
par <- par("mar")
par(mar=rep(3,4))
par(mfrow=c(2,2))
acf(returns_lcc[,"wfc"])
acf(returns_lcc[,"sp500"])
acf(returns_lcc[,"vbltx"])
 acf(returns_lcc[,"aapl"])
# BOx-Pierce test for autocorrelation
btest<-Box.test(returns_lcc[,"wfc"])
# The p value equal to 1 shows no autocorrelation.
# The Ljung-Box test is similar to the simple box.test, generally used for smaller samples.
btest1<-Box.test((returns_lcc[,"wfc"]), type="Ljung-Box")

```

##Partial Autocorrelation (PACF)

Partial Autocorrelation is a tool to understand interrelationships in a time series. It is the condtional correlation between all data points that are exactly n steps apart, after accounting for their correlation with the data between those n steps. It helps to figuring out how many lags to include in the model or the number of autoregression(AR) coefficients in an ARIMA model. For wcf, sp500, vbltx, and aapl no significant partial autocorrelation found. An ACF plot shows the propogation of   correlation at a a gven lag in a time series. However, in order to find lags, the PACF plots are used as these plots accounts correlations between those lags or steps. For example, if a PACF plot has a significant spike only at lag 1, it means that all the higher-order autocorrelations are effectively explained by the lag-1 autocorrelation.


```{r}

par <- par("mar")
par(mar=rep(3,4))
par(mfrow=c(2,2))
pacf(returns_lcc[,"wfc"])
pacf(returns_lcc[,"sp500"])
pacf(returns_lcc[,"vbltx"])
pacf(returns_lcc[,"aapl"])
par(mfrow=c(1,1))

```

##Finding lagged correlation between two time series

The cross correlation function helps to discover lagged correlations between two time series. Correlation at lag 0 is the simple correlation between the variables. Theser is no lagged correlation found in our assets.

```{r,echo= FALSE}
par <- par("mar")
par(mfrow=c(2,2))

ccf((returns_lcc[,"wfc"]),(returns_lcc[,"sp500"]))
cor((returns_lcc[,"wfc"]),(returns_lcc[,"sp500"]))

ccf((returns_lcc[,"vbltx"]),(returns_lcc[,"sp500"]))

ccf((returns_lcc[,"aapl"]),(returns_lcc[,"sp500"]))

ccf((returns_lcc[,"aapl"]),(returns_lcc[,"wfc"]))

```

## Fitting ARIMA Model

Building an ARIMA model consists three steps: 1.Model identification (involves determining the order that is the number of past values and number of past error terms to incorporate in a tentative model, 2.Model estimation (parameters of the model are estimated, generally using either the least squares or maximum likelihood methods), and 3. Diagnostic checking (e.g. Model residuals behave as white noise). The model order is usually denoted by three integers,(p,d,q), where, p= number of autoregressive coeff (AR); d= degree of differencing ; q = number of moving average coeff (MA).
https://onlinecourses.science.psu.edu/stat510/?q=book/export/html/49

```{r}
w<-(auto.arima(returns[,"wfc"]))
#confint(w)
#wcf best order(0,1,0)
auto.arima(returns[,"sp500"])
#sp500 best order(1,1,0)
auto.arima(returns[,"aapl"])
#aapl best order(0,1,0)
auto.arima(returns[,"vbltx"])
#vbltx best order(0,1,2)

```

## Running diagnosis on an ARIMA Model

The tsdiag plots the residuals, the autocorrelation function of the residuals, and the p-values of a Portmanteau test for all lags.

```{r}

tsdiag(w)

```

## Making forcast from an ARIMA Model

The predict function calculates both the next observation and sd according the model.

```{r}

w1<-arima((returns[,"wfc"]),order=c(0,1,0))
predict(w1)
# To predict more than one value.
predict(w1,n.ahead=10)
# Notice that SE grows as each step of prediction.
# visulize the prediction
theForcast<-forecast(w1,h=5)
plot(theForcast)

```

Useful Resources
http://people.duke.edu/~rnau/411arim3.htm (Great explanation of the ACF and PACF concept)

