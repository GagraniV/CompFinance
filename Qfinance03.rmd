---
title: "Describing and modeling finacial time series"
author: "Vijaya Gagrani"
date: "May 2015"
output:
  slidy_presentation: default
  ioslides_presentation:
    keep_md: yes
    transition: faster
    widescreen: yes
  beamer_presentation: default
---

## Background and Objective

The basic assumption for the time series is that the data points are randomly distributed and have some dependency between data points close togather in time but no dependancy in data points far apart in time. These assumptioon can be explained by the stationarity and ergodicity concepts. 

In a stationary stochastic process, the joint distribution of data points is time invariant (i.e., mean and variance doest change over time). The autocovariances and autocorrelations are the measures of linear temporal dependence in a covariance stationary stochastic process, known as autocorrelation function (ACF). The ACF revels the interrelationships within a time series or correlation between all pairs of data points that are exactly same steps appart.

In a strictly stationary or covariance stationary stochastic process no assumption is made about the strength of dependence between random data points in the sequence. The strength of dependence between random points in a stochastic process diminishes the farther apart they become. This diminishing dependence assumption is captured by the concept of ergodicity. A stochastic process is ergodic if any two collections of random points partitioned far apart in the sequence.

An important class of linear time series models is the family of Autoregressive Integrated Moving Average (ARIMA) models, proposed by Box and Jenkins (1976). It assumes that the current value can depend only on the past values of the time series itself or on past values of some error term.

Moving average models are simple covariance stationary and ergodic time series models that can capture a wide variety of autocorrelation patterns. To create a covariance stationary and ergodic stochastic process in which yt and yt minus 1 are correlated but Yt and yt minus j are not correlated for j less then 1, where the time dependence in the process only lasts for one period. These processes can be created using the first order moving average (MA(1)) model. The moving average parameter, theta determines the sign and magnitude of the correlation between yt and yt minus 1. Clearly, if theta equals to 0 then yt exhibits no time dependence.

The presence of autocorrelation is one indication that an ARIMA model could be used to model the time series. From ACF plot, one can count number of significant autocorrelations, which is a useful estimate for the number of moving averages (MA) coefficents in the model. The plot for wfc showsonly one MA coefficent will be required.

```{r Set_ChunkOptions, echo=FALSE}
#Select Chunk and package options @ http://yihui.name/knitr/options
knitr::opts_chunk$set(comment = NA, echo= FALSE, message = FALSE, fig.align='center', warning = FALSE,cache=FALSE)

```
```{r Initial_Settings_n_Basic_Stat}
#set working directory
#setwd("C:/Users/gagranis/Documents/Finance/Coursera/qfinance")
options(digits=4, width=70)
library("forecast")

```
```{r}
# Test for no autocorrelation in returns
par <- par("mar")
par(mar=rep(3,4))
par(mfrow=c(2,2))
acf(returns_lcc[,"wfc"])
acf(returns_lcc[,"sp500"])
acf(returns_lcc[,"vbltx"])
 acf(returns_lcc[,"aapl"])
# BOx-Pierce test  for autocorrelation
Box.test(returns_lcc[,"wfc"])
# The p value equal to 0.95 shows no autocorrelation.
# Ljung-Box test is similar to the simple box.test, generally used for smaller samples.
Box.test((returns_lcc[,"wfc"]), type="Ljung-Box")

```

## Partial Autocorrelation (PACF)

Partial Autocorrelation is a tool to uderstand interrelationships in a time series. It is the correlation between all data points that are excatly n steps apart,after acounting for there correlation with the data betweeen those n steps. It helps to identify the number of autoregression(AR) coefficents in an ARIMA model. For wcf, no significant partial autocorrelation found.

```{r}

par <- par("mar")
par(mar=rep(3,4))
par(mfrow=c(2,2))
pacf(returns_lcc[,"wfc"])
pacf(returns_lcc[,"sp500"])
pacf(returns_lcc[,"vbltx"])
pacf(returns_lcc[,"aapl"])
par(mfrow=c(1,1))

```

##Finding lagged correlation between two time series

The cross correlation function helps to discover lagged correlations between two time series. Correlation at lag 0 is the simple correlation between the variables.

```{r}

ccf((returns_lcc[,"wfc"]),(returns_lcc[,"sp500"]))
cor((returns_lcc[,"wfc"]),(returns_lcc[,"sp500"]))

ccf((returns_lcc[,"vbltx"]),(returns_lcc[,"sp500"]))
ccf((returns_lcc[,"aapl"]),(returns_lcc[,"sp500"]))
ccf((returns_lcc[,"aapl"]),(returns_lcc[,"wfc"]))
 
```
## Fitting ARIMA Model

Building an ARIMA model consists three steps: 1.Model identification (involves determining the order that is the number of past values and number of past error terms to incorporate in a tentative model, 2.Model estimation (parameters of the model are estimated, generally using either the least squares or maximum likelihood methods), and 3. Diagnostic checking(e.g.,model residuals behave as white noise). The model order is usually denoted by three integers,(p,d,q), where, p= number of autoregressive coeff.; d= degree of differencing (AR); q= number of moving average coeff (MA).

```{r}
w<-(auto.arima(returns[,"wfc"]))
confint(w)
#wcf best order(0,1,0)
auto.arima(returns[,"sp500"])
#sp500 best order(1,1,0)
auto.arima(returns[,"aapl"])
#aapl best order(0,1,0)
auto.arima(returns[,"vbltx"])
#vbltx best order(0,1,2)
```
## Running diagnosis on an ARIMA Model
```{r}
tsdiag(w)
```
## Making forcast from an ARIMA Model
The predict function calculates both the next observation and sd according the model.

```{r}
w1<-arima((returns[,"wfc"]),order=c(0,1,0))
predict(w1)
# To predict more than one value.
predict(w1,n.ahead=10)
# Notice that SE grows as each step of prediction.
# visulize the prediction
theForcast<-forecast(w1,h=5)
plot(theForcast)

```
```{r}
Interest rates are downloaded from the FRED (Federal Reserve Economic Data) data source.
var1 <- VAR(dataDaily, lag.max=4, ic="AIC")
rugarch, rmgarch (for multivariate models), 
library (Quantmod)

```
## Volatility forcasting for risk managmnet
Financial institutions measure the risk using a Value-at-Risk (VaR), usually calculated at the 99% confidence level. For stock proces, the low volatility period is followed by periods of high volatility and vice versa. This phenomenon is the base assumption in ARCH('Autoregressive Conditional Heteroskedasticity) model. A simple line plot of returns shows it.  We can test it by using two commonly uded tests(â€¢The Ljung-Box test for autocorrelation in squared returns and the Lagrange Multiplier (LM)).
For financial time series model GARCH is commonly used. In rugarch library there are diffrent functions for model specification, parameter estimation, backtesting, and forecasting. 
```{r}
Box.test(coredata(intc^2), type = "Ljung-Box", lag = 12)
#Reject the null hypothesis of no autocorrelations in the squared returns at the 1% significance level
install.packages("FinTS")
library("FinTS")
ArchTest(coredata(intc))

library("rugarch")
#specify the model
intc_garch11_spec <- ugarchspec(variance.model = list(+   garchOrder = c(1, 1)),+  mean.model = list(armaOrder = c(0, 0)))
#model estimation
intc_garch11_fit <- ugarchfit(spec = intc_garch11_spec,+  data = intc)
#backtesting: to check the model perfromance 
intc_garch11_roll <- ugarchroll(intc_garch11_spec, intc,+   n.start = 120, refit.every = 1, refit.window = "moving",+   solver = "hybrid", calculate.VaR = TRUE, VaR.alpha = 0.01,+   keep.coef = TRUE)
#examining backtest report
report(intc_garch11_roll, type = "VaR", VaR.alpha = 0.01,+   conf.level = 0.99)
#Kupiec's unconditional coverage compares the number of expected versus actual exceedances given the tail probability of VaR, while the Christoffersen test is a joint test of the unconditional coverage and the independence of the exceedances. In our case, despite the actual five exceedances versus an expectation of three, we can't reject the null hypothesis that the exceedances are correct and independent.
intc_VaR <- zoo(intc_garch11_roll@forecast$VaR[, 1])
index(intc_VaR) <- as.yearmon(rownames(intc_garch11_roll@forecast$VaR))
intc_actual <- zoo(intc_garch11_roll@forecast$VaR[, 2])
index(intc_actual) <- as.yearmon(rownames(intc_garch11_roll@forecast$VaR))
plot(intc_actual, type = "b", main = "99% 1 Month VaR Backtesting",+   xlab = "Date", ylab = "Return/VaR in percent")
lines(intc_VaR, col = "red")
legend("topright", inset=.05, c("Intel return","VaR"), col = c("black","red"), lty = c(1,1))
#forecasting
intc_garch11_fcst <- ugarchforecast(intc_garch11_fit, n.ahead = 12)


```


