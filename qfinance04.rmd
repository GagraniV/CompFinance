---
title: "Finacial risk volatility modeling (ARCH, GARCH, & EGRCH) with R"
author: "Vijaya Gagrani"
date: "May 2015"
output:
  slidy_presentation: default
  ioslides_presentation:
  keep_md: yes
  transition: faster
  widescreen: yes
  beamer_presentation: default
---
   
```{r Set_ChunkOptions, echo=FALSE}
#Select Chunk and package options @ http://yihui.name/knitr/options
knitr::opts_chunk$set(comment = NA, echo= FALSE, message = FALSE, fig.align='center', warning = FALSE,cache=FALSE)
```
## Background and Objective

Finacial risk univariate volatility models included in this analyis are ARCH, GARCH, and EGRCH. These models are based on a least squares models assumptions that the expected value of all squared error terms or variance is same at any given point (homoskendasticity). The opposite concept is heterskendasticity, where variance of the error term is not constant for all points, and thats what the center of the Autoregressive Conditional Heteroskedasticity models (ARCH).

Volatility is important in quantifiying financial risk, portfolio selection, derivative pricing, and option pricing model. However, in financial time series, volatility occurs in clusters like periods of high volatility follows with high volatility and vice versa.  In addtion, more recent events would be more relevant then the distant past events. The ARCH models utilize the heteroskedasticity in time series data to measure volatility (standard deviation). These models are applied to forecast mean, SD, and variance of return based on the past information. In addtion, these models allow to use the best weights in forecasting variance instead of using equal weights for all past events.

An ARCH model is similar to the AR(1) model on squared residuals. In an ARCH(1) model, next period’s variance only depends on last period’s squared residual. The ARCH model is extended as the Generalized ARCH or GARCH model by making variance conditional to both squared residuals and squared observations in past. The typical GARCH model is described as GARCH(1,1) model. The first subscript in GARCH reefers to autoregressive lags or ARCH and second subscript refers to the moving average lags, respectively. These models are basically setup for one period forecast, however a long-horizon forecasting can be constructed. The ARCH/GARCH approaches are widely used in situations where volatility of return is a central issue.  

However,it is also well established that the volatility is more influenced by negative returns then the postive(leverage effect). The nonlinear GARCH, exponetial GARCH, and threshold GARCH models accounts the leverage effect. It is important to understand that the standard GARCH assumnes that the model residuals are normally distrbuted, however returns on assests are often skewed or leptokurtosisic. 

The clustered volatilty phenomenon in finacial data is visually detectable in simple line plots. In addtion, we can identify it by applying two commonly used tests, first is the Ljung-Box test for autocorrelation in squared returns and second is the Lagrange Multiplier (LM test). In rugarch library there are diffrent functions for model specification, parameter estimation, backtesting, and forecasting. 

```{r Initial_Settings_n_Basic_Stat}
#set working directory
#setwd("C:/Users/gagranis/Documents/Finance/Coursera/qfinance")
options(digits=4, width=70)
library("PerformanceAnalytics")
library("xts")
library("zoo")
library("tseries")
library("plyr")
library("mvtnorm")
library("splusTimeSeries")
library("boot")
library("FinTS") #  for LM test
library("rugarch")
```

## Testing ARCH Effect or No autocorrelation

For a single assest, we are using wfc monthly closing prices. First, the monthly return is calcualted using the monthly price data. Monthly returns are stationaly, whereas monthly price is nonstationary. The Ljung-Box test and the Lagrange Multiplier indicated no autocorrelation exists in outmonthly return.

```{r}

# the wfc_sim_pret is simple monthly(%) return.
 
wfc_sim_pret[which.min(wfc_sim_pret)]
# The largest one month loass for wfc was -36%.

plot(wfc_sim_pret,main="MOnthly Simple Return on WFC", xlab = "Days", ylab="Return in %")

#Coredata function eliminates any index and provides the data field only.. 
Box.test(coredata(wfc_sim_pret^2), type = "Ljung-Box", lag = 12)
#Reject the null hypothesis that there is no autocorrelations in the squared returns at the 1% significance level

#LM test (FinTS package)

ArchTest(coredata(wfc_sim_pret))
#The above two tests confirm that ARCH effect (no autocorrelation) exists in the monthly simple return

```

## GARCH Model
http://faculty.washington.edu/ezivot/econ589/ch18-garch.pdf
http://faculty.washington.edu/ezivot/econ584/notes/timeSeriesConcepts.pdf
http://www.inside-r.org/packages/cran/rugarch/docs/ugarchspec (garchOrder The ARCH (q) and GARCH (p) orders.)
Lander, J. P. (2014). R for everyone: Advanced analytics and graphics. Pearson Education.(Chapter 21. Time Series and Autocorrelation).
http://unstarched.net/r-examples/rugarch/a-short-introduction-to-the-rugarch-package/


```{r}
#1.specify the model using the Univariate GARCH Specification or ugarchspec function from the  rugarch library.
# mean to be modeled as an ARMA(1, 1) and for the white noise (0,0).
wfc_garch_11_spec<- ugarchspec(variance.model = list(garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0)))

#2.model estimation
wfc_garch_11_fit <- ugarchfit(spec = wfc_garch_11_spec,data = wfc_sim_pret)

wfc_garch_11_fit
# How to read GARCH Model Fit???

#3.backtesting: to check the model perfromance 

wfc_garch_11_roll <- ugarchroll(wfc_garch_11_spec, wfc_sim_pret, n.start = 120, refit.every = 1, refit.window = "moving",solver = "hybrid", calculate.VaR = TRUE, VaR.alpha = 0.01,keep.coef = TRUE)

#4. examining backtest report
report(wfc_garch_11_roll, type = "VaR", VaR.alpha = 0.01,conf.level = 0.99)

#Kupiec's unconditional coverage compares the number of expected versus actual exceedances given the tail probability of VaR, while the Christoffersen test is a joint test of the unconditional coverage and the independence of the exceedances. In our case, despite the actual 2 exceedances versus an expectation of 1.3, we can't reject the null hypothesis that the exceedances are correct and independent.

wfc_VaR <- zoo(wfc_garch_11_roll@forecast$VaR[, 1])

#index(wfc_VaR) <- as.yearmon(rownames(intc_garch11_roll@forecast$VaR))

wfc_actual <- zoo(wfc_garch_11_roll@forecast$VaR[, 2])

#index(intc_actual) <- as.yearmon(rownames(intc_garch11_roll@forecast$VaR))

plot(wfc_actual, type = "b", main = "99% 1 Month VaR Backtesting",xlab = "Date", ylab = "Return/VaR in percent")
lines(wfc_VaR, col = "red")

legend("topright", inset=.05, c("wfc return","VaR"), col = c("black","red"), lty = c(1,1))

#forecasting
wfc_garch_11_fcst <- ugarchforecast(wfc_garch_11_fit, n.ahead = 12)
qnorm(.99)*3.660

```

## Vector Autoregressive Models (VAR) with R

The Vector autoregressive models (VAR) are the multivariate extensions of the univariate autoregressive (AR) models, captures the linear dependencies among multiple time series. As per the VAR model each variable is evolved through a linear function of all other lagged variables. All variables depends on the past values of its own as well as the other variables in consideration. For a VAR model, all variables have to be stationary, else show the same order of integration. In case if the variables are nonstationary, or cointegrated, the error correction term is included in the VAR and the model is known as Vector Error Correction Model (VECM). 

More than one assests can be modeled using the multivariate ARCH/GARCH model often known as the VEC-GARCH model (Vector Error Correction Models), replacing the volatility parameter with the covariance matrix.

A nonstationary time series have means, variances, and covariances that change over time. The nonstationary time series shows the stocastic trends, cycles, random walks, or combinations of the three. Regression models without accounting the nonstationarity results into spurious regressions (situation like when two economic variables seems related over time, but in fact they are not). Cointegration technique is useful to investigate the cointegrated or nonstationary variables. If all variables in an econometric model share a common stochastic trend, the cointegration analysis uncovers the long-term relationship and the short-term dynamics while controling the spurious regression problem.The following two tests: the Engle-Granger and the Johansen-Juselius are used to test the cointegration. 
(http://denizstij.blogspot.com/2013/11/cointegration-tests-adf-and-johansen.html
https://cran.r-project.org/web/packages/egcm/egcm.pdf)
Augmented Dickey–Fuller (ADF) t-statistic test: small p-values suggest (library(urca)).

A VAR model is primarily used to assess the Impulse-response from a stress. Essentially, an impulse-response function shows how a variable reacts (response) to a shock (impulse) influencing any other variable in the system. For example the impulse response of 1SD shock in S&P prices for an univariate analysis. For multivariate analysis, covariance matrix is used.
In this analysis following three datasets are used:
1. Equity Return (wfc)
2. Stock Index (S&P500)
3. US Treasury bond interest rates
The primary purpose is to make a forecast for the S&P index by using two additional variables and to identify impulse responses. The above three variable holds a long term relationship.

The main advantage with SVAR analysis is that the necessary restrictions on the estimated reduced VAR model, required for identification of the underlying structural model, can be provided by economic theory.These restrictions can be either contemporaneous or long-run in nature depending on whether the underlying disturbances are considered to be temporary or permanent in nature. Once the identification is achieved it is possible to recover the structural shocks. These shocks can then be used to generate impulse response and variance decomposition functions to assess the dynamic impacts of different economic variables. In addition these functions can be used to test whether such shocks affect the economic variables as economic theory would predict so providing a check on the theory.

```{}
# data download, Interest rates are downloaded from the FRED (Federal Reserve Economic Data) data source. rest two are from yahoo finance.
#The R package, "vars" provide an excellent framework for this analysis.
# Important R packages for this analysis are vars and quantmod.

getSymbols('MSFT', from='2004-01-02', to='2014-03-31')
getSymbols('SNP', from='2004-01-02', to='2014-03-31')
getSymbols('DTB3', src='FRED')
plot...
#Reduced VAR model
var1 <- VAR(dataDaily, lag.max=4, ic="AIC")
VARselect(dataDaily,lag.max=4)
summary(var1)

var.pred <- predict(var1, n.ahead=10, ci=0.95)
var.irf <- irf(var1)
plot(var.irf)
#structural VAR

#SVAR

```

Berlinger, E., Illés, F., Badics, M., Banai, Á., Daróczi, G., Dömötör, B., ... & Vidovics-Dancs, Á. (2015). Mastering R for Quantitative Finance. Packt Publishing Ltd.

Fabozzi, F. J., Focardi, S. M., Rachev, S. T., & Arshanapalli, B. G. (2014). The Basics of Financial Econometrics: Tools, Concepts, and Asset Management Applications. John Wiley & Sons.

http://www.investopedia.com

http://www.cmat.edu.uy/~mordecki/hk/engle.pdf
http://faculty.washington.edu/ezivot/econ589/econ589univariateGarch.r
http://faculty.washington.edu/ezivot/econ589/univariateGarch2012powerpoint.pdf
http://www.r-bloggers.com/a-practical-introduction-to-garch-modeling/
https://onlinecourses.science.psu.edu/stat510/node/61
